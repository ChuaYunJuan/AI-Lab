{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Train Test Splits, Cross Validation, and Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "We will be working with a data set based on [housing prices in Ames, Iowa](https://www.kaggle.com/c/house-prices-advanced-regression-techniques). It was compiled for educational use to be a modernized and expanded alternative to the well-known Boston Housing dataset. This version of the data set has had some missing values filled for convenience.\n",
    "\n",
    "There are an extensive number of features, so they've been described in the table below.\n",
    "\n",
    "### Predictor\n",
    "\n",
    "* SalePrice: The property's sale price in dollars. \n",
    "\n",
    "\n",
    "### Features\n",
    "\n",
    "<table>\n",
    "  <tbody>    \n",
    "    <tr valign=\"top\">\n",
    "      <td valign=\"top\">\n",
    "        <ul>\n",
    "          <li>MoSold: Month Sold</li>\n",
    "          <li>YrSold: Year Sold</li><br>\n",
    "          <li>SaleType: Type of sale</li>\n",
    "          <li>SaleCondition: Condition of sale</li><br>\n",
    "          <li>MSSubClass: The building class</li>\n",
    "          <li>MSZoning: The general zoning classification</li><br>\n",
    "          <li>Neighborhood: Physical locations within Ames city limits</li>\n",
    "          <li>Street: Type of road access</li>\n",
    "          <li>Alley: Type of alley access</li><br>\n",
    "          <li>LotArea: Lot size in square feet</li>\n",
    "          <li>LotConfig: Lot configuration</li>\n",
    "          <li>LotFrontage: Linear feet of street connected to property</li>\n",
    "          <li>LotShape: General shape of property</li><br>\n",
    "          <li>LandSlope: Slope of property</li>\n",
    "          <li>LandContour: Flatness of the property</li><br>\n",
    "          <li>YearBuilt: Original construction date</li>\n",
    "          <li>YearRemodAdd: Remodel date</li>\n",
    "          <li>OverallQual: Overall material and finish quality</li>\n",
    "          <li>OverallCond: Overall condition rating</li><br>\n",
    "          <li>Utilities: Type of utilities available</li>\n",
    "          <li>Foundation: Type of foundation</li>\n",
    "          <li>Functional: Home functionality rating</li><br>\n",
    "          <li>BldgType: Type of dwelling</li>\n",
    "          <li>HouseStyle: Style of dwelling</li><br>\n",
    "          <li>1stFlrSF: First Floor square feet</li>\n",
    "          <li>2ndFlrSF: Second floor square feet</li>\n",
    "          <li>LowQualFinSF: Low quality finished square feet (all floors)</li>\n",
    "          <li>GrLivArea: Above grade (ground) living area square feet</li>\n",
    "          <li>TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)</li><br>\n",
    "          <li>Condition1: Proximity to main road or railroad</li>\n",
    "          <li>Condition2: Proximity to main road or railroad (if a second is present)</li><br>\n",
    "          <li>RoofStyle: Type of roof</li>\n",
    "          <li>RoofMatl: Roof material</li><br>\n",
    "          <li>ExterQual: Exterior material quality</li>\n",
    "          <li>ExterCond: Present condition of the material on the exterior</li>\n",
    "          <li>Exterior1st: Exterior covering on house</li>\n",
    "          <li>Exterior2nd: Exterior covering on house (if more than one material)</li><br><br>\n",
    "        </ul>\n",
    "      </td>\n",
    "      <td valign=\"top\">\n",
    "        <ul>\n",
    "          <li>MasVnrType: Masonry veneer type</li>\n",
    "          <li>MasVnrArea: Masonry veneer area in square feet</li><br>\n",
    "          <li>WoodDeckSF: Wood deck area in square feet</li>\n",
    "          <li>OpenPorchSF: Open porch area in square feet</li>\n",
    "          <li>EnclosedPorch: Enclosed porch area in square feet</li>\n",
    "          <li>3SsnPorch: Three season porch area in square feet</li>\n",
    "          <li>ScreenPorch: Screen porch area in square feet</li><br>\n",
    "          <li>PoolArea: Pool area in square feet</li>\n",
    "          <li>PoolQC: Pool quality</li>\n",
    "          <li>Fence: Fence quality</li>\n",
    "          <li>PavedDrive: Paved driveway</li><br>\n",
    "          <li>GarageType: Garage location</li>\n",
    "          <li>GarageYrBlt: Year garage was built</li>\n",
    "          <li>GarageFinish: Interior finish of the garage</li>\n",
    "          <li>GarageCars: Size of garage in car capacity</li>\n",
    "          <li>GarageArea: Size of garage in square feet</li>\n",
    "          <li>GarageQual: Garage quality</li>\n",
    "          <li>GarageCond: Garage condition</li><br>\n",
    "          <li>Heating: Type of heating</li>\n",
    "          <li>HeatingQC: Heating quality and condition</li>\n",
    "          <li>CentralAir: Central air conditioning</li>\n",
    "          <li>Electrical: Electrical system</li><br>\n",
    "          <li>FullBath: Full bathrooms above grade</li>\n",
    "          <li>HalfBath: Half baths above grade</li><br>\n",
    "          <li>BedroomAbvGr: Number of bedrooms above basement level</li><br>\n",
    "          <li>KitchenAbvGr: Number of kitchens</li>\n",
    "          <li>KitchenQual: Kitchen quality</li><br>\n",
    "          <li>Fireplaces: Number of fireplaces</li>\n",
    "          <li>FireplaceQu: Fireplace quality</li><br>\n",
    "          <li>MiscFeature: Miscellaneous feature not covered in other categories</li>\n",
    "          <li>MiscVal: Value of miscellaneous feature</li><br>\n",
    "          <li>BsmtQual: Height of the basement</li>\n",
    "          <li>BsmtCond: General condition of the basement</li>\n",
    "          <li>BsmtExposure: Walkout or garden level basement walls</li>\n",
    "          <li>BsmtFinType1: Quality of basement finished area</li>\n",
    "          <li>BsmtFinSF1: Type 1 finished square feet</li>\n",
    "          <li>BsmtFinType2: Quality of second finished area (if present)</li>\n",
    "          <li>BsmtFinSF2: Type 2 finished square feet</li>\n",
    "          <li>BsmtUnfSF: Unfinished square feet of basement area</li>\n",
    "          <li>BsmtFullBath: Basement full bathrooms</li>\n",
    "          <li>BsmtHalfBath: Basement half bathrooms</li>\n",
    "          <li>TotalBsmtSF: Total square feet of basement area</li>\n",
    "        </ul>\n",
    "      </td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T17:24:40.724060Z",
     "start_time": "2017-03-09T12:24:40.718739-05:00"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "filepath = \"D:\\\\UTAR\\\\Degree\\\\Y3S1\\\\Artificial Intelligence\\AI_Practical_Github\\\\AI_Week 5\\\\Topic_2_Optimizing_Data_For_Supervised_Learning_Notebook_Questions\\\\Ames_Housing_Sales.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Question 1\n",
    "\n",
    "* Import the data using Pandas and examine the shape. There are 79 feature columns plus the predictor, the sale price (`SalePrice`). \n",
    "* There are three different types: integers (`int64`), floats (`float64`), and strings (`object`, categoricals). Examine how many there are of each data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "# Import the data using the file path\n",
    "data = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     43\n",
       "float64    21\n",
       "int64      16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display value counts of data set\n",
    "data.shape\n",
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Question 2\n",
    "\n",
    "As discussed in the lecture, a significant challenge, particularly when dealing with data that have many columns, is ensuring each column gets encoded correctly. \n",
    "\n",
    "This is particularly true with data columns that are ordered categoricals (ordinals) vs unordered categoricals. Unordered categoricals should be one-hot encoded, however this can significantly increase the number of features and creates features that are highly correlated with each other.\n",
    "\n",
    "Determine how many total features would be present, relative to what currently exists, if all string (object) features are one-hot encoded. Recall that the total number of one-hot encoded columns is `n-1`, where `n` is the number of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "Index(['Alley', 'BldgType', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\n",
      "       'BsmtFinType2', 'BsmtQual', 'CentralAir', 'Condition1', 'Condition2',\n",
      "       'Electrical', 'ExterCond', 'ExterQual', 'Exterior1st', 'Exterior2nd',\n",
      "       'Fence', 'FireplaceQu', 'Foundation', 'Functional', 'GarageCond',\n",
      "       'GarageFinish', 'GarageQual', 'GarageType', 'Heating', 'HeatingQC',\n",
      "       'HouseStyle', 'KitchenQual', 'LandContour', 'LandSlope', 'LotConfig',\n",
      "       'LotShape', 'MSZoning', 'MasVnrType', 'MiscFeature', 'Neighborhood',\n",
      "       'PavedDrive', 'PoolQC', 'RoofMatl', 'RoofStyle', 'SaleCondition',\n",
      "       'SaleType', 'Street', 'Utilities'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Select the object (string) columns \n",
    "category_columns = data.columns[data.dtypes == 'object']\n",
    "print(len(category_columns))\n",
    "print(category_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alley             2\n",
      "Street            2\n",
      "CentralAir        2\n",
      "Utilities         2\n",
      "PoolQC            3\n",
      "BsmtCond          3\n",
      "PavedDrive        3\n",
      "MasVnrType        3\n",
      "GarageFinish      3\n",
      "LandSlope         3\n",
      "BsmtExposure      4\n",
      "BsmtQual          4\n",
      "MiscFeature       4\n",
      "ExterCond         4\n",
      "ExterQual         4\n",
      "LotShape          4\n",
      "Fence             4\n",
      "KitchenQual       4\n",
      "LandContour       4\n",
      "BsmtFinType1      5\n",
      "HeatingQC         5\n",
      "LotConfig         5\n",
      "MSZoning          5\n",
      "GarageQual        5\n",
      "BldgType          5\n",
      "GarageCond        5\n",
      "FireplaceQu       5\n",
      "Electrical        5\n",
      "SaleCondition     6\n",
      "RoofStyle         6\n",
      "BsmtFinType2      6\n",
      "GarageType        6\n",
      "Heating           6\n",
      "Foundation        6\n",
      "Functional        7\n",
      "RoofMatl          8\n",
      "HouseStyle        8\n",
      "Condition2        8\n",
      "Condition1        9\n",
      "SaleType          9\n",
      "Exterior1st      14\n",
      "Exterior2nd      16\n",
      "Neighborhood     25\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_ohe_columns = data[category_columns].apply(lambda x: x.nunique()).sort_values(ascending=True)\n",
    "print(number_of_ohe_columns)\n",
    "number_of_ohe_columns = number_of_ohe_columns - 1 \n",
    "number_of_ohe_columns.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# Determine how many extra columns would be created\n",
    "\n",
    "\n",
    "# No need to encode if there is only one value\n",
    "\n",
    "# Number of one-hot columns is one less than the number of categories\n",
    "\n",
    "# This is 215 columns, assuming the original ones are dropped. \n",
    "# This is quite a few extra columns!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Question 3\n",
    "\n",
    "Let's create a new data set where all of the above categorical features will be one-hot encoded. We can fit this data and see how it affects the results.\n",
    "\n",
    "* Used the dataframe `.copy()` method to create a completely separate copy of the dataframe for one-hot encoding\n",
    "* On this new dataframe, one-hot encode each of the appropriate columns and add it back to the dataframe. Be sure to drop the original column.\n",
    "* For the data that are not one-hot encoded, drop the columns that are string categoricals.\n",
    "\n",
    "For the first step, numerically encoding the string categoricals, either Scikit-learn;s `LabelEncoder` or `DictVectorizer` can be used. However, the former is probably easier since it doesn't require specifying a numerical value for each category, and we are going to one-hot encode all of the numerical values anyway. (Can you think of a time when `DictVectorizer` might be preferred?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Copy of the data\n",
    "data_ohc = data.copy()\n",
    "\n",
    "# The encoders\n",
    "le = LabelEncoder()\n",
    "ohc = OneHotEncoder(categories='auto')\n",
    "\n",
    "for col in category_columns:\n",
    "   \n",
    "    # Integer encode the string categories\n",
    "    dat = le.fit_transform(data_ohc[col]).astype(int)\n",
    "    \n",
    "    # Remove the original column from the dataframe\n",
    "    data_ohc = data_ohc.drop(col, axis=1)\n",
    "\n",
    "    # One hot encode the data--this returns a sparse array\n",
    "    new_dat = ohc.fit_transform(dat.reshape(-1,1))\n",
    "\n",
    "    # Create unique column names\n",
    "    n_cols = new_dat.shape[1]\n",
    "    col_names = ['_'.join([col, str(x)]) for x in range(n_cols)]\n",
    "\n",
    "    # Create the new dataframe\n",
    "    new_df = pd.DataFrame(new_dat.toarray(), index=data_ohc.index, columns=col_names)\n",
    "\n",
    "    # Append the new data to the dataframe\n",
    "    data_ohc = pd.concat([data_ohc, new_df], axis=1)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1379, 295)\n"
     ]
    }
   ],
   "source": [
    "# Column difference is as calculated above\n",
    "data_ohc.shape[1] - data.shape[1]\n",
    "\n",
    "# Remove the string columns from the dataframe\n",
    "dara_ohc = data.drop(category_columns, axis=1)\n",
    "\n",
    "\n",
    "#print shape of data\n",
    "print(data_ohc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Question 4\n",
    "\n",
    "* Create train and test splits of both data sets. To ensure the data gets split the same way, use the same `random_state` in each of the two splits.\n",
    "* For each data set, fit a basic linear regression model on the training data. \n",
    "* Calculate the mean squared error on both the train and test sets for the respective models. Which model produces smaller error on the test data and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "chosen_state_number = 42\n",
    "\n",
    "y_col = 'SalePrice'\n",
    "\n",
    "# Use the correct dataframe for feature columns\n",
    "feature_cols = [x for x in data.columns if x != y_col]\n",
    "x_data = data[feature_cols]\n",
    "y_data = data[y_col]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3, random_state=chosen_state_number)\n",
    "\n",
    "feature_cols_ohc = [x for x in data_ohc.columns if x != y_col]\n",
    "x_data_ohc = data_ohc[feature_cols_ohc]\n",
    "y_data_ohc = data_ohc[y_col]\n",
    "\n",
    "x_train_ohc, x_test_ohc, y_train_ohc, y_test_ohc = train_test_split(x_data_ohc, y_data_ohc, test_size=0.3, random_state=chosen_state_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_3</th>\n",
       "      <th>SaleType_4</th>\n",
       "      <th>SaleType_5</th>\n",
       "      <th>SaleType_6</th>\n",
       "      <th>SaleType_7</th>\n",
       "      <th>SaleType_8</th>\n",
       "      <th>Street_0</th>\n",
       "      <th>Street_1</th>\n",
       "      <th>Utilities_0</th>\n",
       "      <th>Utilities_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>630.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>515.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>845.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>728.0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>728.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>561.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>1601.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 294 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "461      630.0       0.0        0.0             1       515.0         0.0   \n",
       "976      845.0       0.0        0.0             3         0.0         0.0   \n",
       "1128     728.0     728.0        0.0             3         0.0         0.0   \n",
       "904      561.0     668.0        0.0             2       285.0         0.0   \n",
       "506     1601.0       0.0        0.0             3      1358.0         0.0   \n",
       "\n",
       "      BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch  ...  SaleType_3  \\\n",
       "461              1             0      115.0            0.0  ...         0.0   \n",
       "976              0             0        0.0            0.0  ...         0.0   \n",
       "1128             0             0      728.0            0.0  ...         0.0   \n",
       "904              0             0      276.0            0.0  ...         0.0   \n",
       "506              1             0      223.0            0.0  ...         0.0   \n",
       "\n",
       "      SaleType_4  SaleType_5  SaleType_6  SaleType_7  SaleType_8  Street_0  \\\n",
       "461          0.0         0.0         0.0         0.0         1.0       0.0   \n",
       "976          0.0         0.0         0.0         0.0         1.0       0.0   \n",
       "1128         0.0         0.0         0.0         0.0         1.0       0.0   \n",
       "904          0.0         0.0         0.0         0.0         1.0       0.0   \n",
       "506          0.0         0.0         0.0         0.0         1.0       0.0   \n",
       "\n",
       "      Street_1  Utilities_0  Utilities_1  \n",
       "461        1.0          1.0          0.0  \n",
       "976        1.0          1.0          0.0  \n",
       "1128       1.0          1.0          0.0  \n",
       "904        1.0          1.0          0.0  \n",
       "506        1.0          1.0          0.0  \n",
       "\n",
       "[5 rows x 294 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_ohc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.index == x_train_ohc.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data MSE is 317726663.47075474\n",
      "Testing data MSE is 162903748260286.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "LR = LinearRegression()\n",
    "\n",
    "# Ensure all categorical features are properly encoded\n",
    "x_train_encoded = pd.get_dummies(x_train)\n",
    "x_test_encoded = pd.get_dummies(x_test)\n",
    "\n",
    "# Align the train and test data to ensure they have the same columns\n",
    "x_train_encoded, x_test_encoded = x_train_encoded.align(x_test_encoded, join='left', axis=1, fill_value=0)\n",
    "\n",
    "LR = LR.fit(x_train_encoded, y_train)\n",
    "y_train_pred = LR.predict(x_train_encoded)\n",
    "y_test_pred = LR.predict(x_test_encoded)\n",
    "\n",
    "print(\"Training data MSE is\", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Testing data MSE is\", mean_squared_error(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "Note that the error values on the one-hot encoded data are very different for the train and test data. In particular, the errors on the test data are much higher. Based on the lecture, this is because the one-hot encoded model is overfitting the data. We will learn how to deal with issues like this in the next lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Question 5\n",
    "\n",
    "For each of the data sets (one-hot encoded and not encoded):\n",
    "\n",
    "* Scale the all the non-hot encoded values using one of the following: `StandardScaler`, `MinMaxScaler`, `MaxAbsScaler`.\n",
    "* Compare the error calculated on the test sets\n",
    "\n",
    "Be sure to calculate the skew (to decide if a transformation should be done) and fit the scaler on *ONLY* the training data, but then apply it to both the train and test data identically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mute the setting with a copy warnings\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Question 6\n",
    "\n",
    "Plot predictions vs actual for one of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "name": "Train_Test_Splits_Regularization_Exercises-ANSWERS",
  "notebookId": 2125319687183944
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
